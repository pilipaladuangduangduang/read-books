# 阿里文档受益良多

标签（空格分隔）： 

---

今天阿里公布了它们对Java的规范和常用的一些知识，我花了两个小时通读了一遍，受益良多，如下：

1、所有的 POJO 类属性必须使用包装数据类型，局部变量【推荐】使用基本数据类型，RPC 方法的返回值和参数必须使用包装数据类型；
	 
2、final 可提高程序响应效率，声明成 final 的情况：
	  
 - 不需要重新赋值的变量，包括类属性、局部变量；
	  
 - 对象参数前加 final ，表示不允许修改引用的指向；
	  
 - 类方法确定不允许被重写；
	  
3、不要在 foreach 循环里进行元素的 remove / add 操作； remove 元素请使用 Iterator 方式，如果并发操作，需要对 Iterator 对象加锁；

4、遍历Map，如果是 JDK 8，使用 Map.foreach 方法；其次用enrtySet遍历；
		
5、利用 Set 元素唯一的特性，可以快速对一个集合进行去重操作，避免使用 List 的 contains 方法进行遍历、对比、去重操作；

6、线程资源必须通过线程池提供，不允许在应用中自行显式创建线程；

7、线程池不允许使用 Executors 去创建，而是通过 new ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险；
		
8、SimpleDateFormat是线程不安全的类，在并发情况下可以这样使用：

``` java
private static final ThreadLocal<DateFormat> df = new ThreadLocal<DateFormat>() {
	@ Override
	protected DateFormat initialValue() {
		return new SimpleDateFormat("yyyy-MM-dd");
	}
};
```
		
如果是 JDK 8 的应用，可以使用 Instant 代替 Date ， LocalDateTime 代替 Calendar ，DateTimeFormatter 代替 Simpledateformatter ，官方给出的解释： simple beautiful strong immutable thread - safe ；

9、使用 CountDownLatch 进行异步转同步操作，每个线程退出前必须调用 countDown 方法，线程执行代码注意 catch 异常，确保 countDown 方法可以执行，避免主线程无法执行至 countDown 方法，直到超时才返回结果；

10、避免 Random 实例被多线程使用，虽然共享该实例是线程安全的，但会因竞争同一 seed 导致的性能下降；在 JDK 7 之后，可以直接使用 API ThreadLocalRandom ，在  JDK 7 之前，可以做到每个线程一个实例；

11、volatile 解决多线程内存不可见问题；对于一写多读，是可以解决变量同步问题，但是如果多写，同样无法解决线程安全问题； 如果是 JDK 8，推荐使用 LongAdder 对象，比 AtomicLong 性能更好 （ 减少乐观锁的重试次数 ） ；

12、HashMap 在容量不够进行 resize 时由于高并发可能出现死链，导致 CPU 飙升，在开发过程中注意规避此风险；

13、ThreadLocal 无法解决共享对象的更新问题， ThreadLocal 对象建议使用 static修饰；这个变量是针对一个线程内所有操作共有的，所以设置为静态变量，所有此类实例共享此静态变量 ，也就是说在类第一次被使用时装载，只分配一块存储空间，所有此类的对象 ( 只要是这个线程内定义的 ) 都可以操控这个变量；

14、在一个 switch 块内，都必须包含一个 default 语句并且放在最后，即使它什么代码也没有；

15、如果非得使用 if()...else if()...else... 方式表达逻辑，【强制】请勿超过 3 层，超过请使用状态设计模式；

16、循环体中的语句要考量性能，以下操作尽量移至循环体外处理，如定义对象、变量、获取数据库连接

17、方法中需要进行参数校验的场景：

 - 调用频次低的方法；

 - 执行时间开销很大的方法，参数校验时间几乎可以忽略不计，但如果因为参数错误导致中间执行回退，或者错误，那得不偿失；

 - 需要极高稳定性和可用性的方法；

 - 对外提供的开放接口，不管是 RPC / API / HTTP 接口；

 - 敏感权限入口；

18、方法中不需要参数校验的场景：

 - 极有可能被循环调用的方法，不建议对参数进行校验；但在方法说明里必须注明外部参数检查；

 - 底层的方法调用频度都比较高，一般不校验；毕竟是像纯净水过滤的最后一道，参数错误不太可能到底层才会暴露问题；一般 DAO 层与 Service 层都在同一个应用中，部署在同一台服务器中，所以 DAO 的参数校验，可以省略；

 - 被声明成 private 只会被自己代码所调用的方法，如果能够确定调用方法的代码传入参数已经做过检查或者肯定不会有问题，此时可以不校验参数；

19、方法内部单行注释，在被注释语句上方另起一行，使用//注释；方法内部多行注释使用/* */注释，注意与代码对齐；

20、后台输送给页面的变量必须加 $!{var} ——中间的感叹号；说明：如果 var = null 或者不存在，那么 ${var} 会直接显示在页面上；

21、获取当前毫秒数 System . currentTimeMillis(); 而不是 new Date() . getTime();说明：如果想获取更加精确的纳秒级时间值，用 System . nanoTime() ；在 JDK 8 中，针对统计时间等场景，推荐使用 Instant 类；

22、任何数据结构的构造或初始化，都应指定大小，避免数据结构无限增长吃光内存；

23、不要捕获 Java 类库中定义的继承自 RuntimeException 的运行时异常类，如：IndexOutOfBoundsException / NullPointerException，这类异常由程序员预检查来规避，保证程序健壮性；

24、不能在 finally 块中使用 return ， finally 块中的 return 返回后方法结束执行，不会再执行 try 块中的 return 语句；

25、防止 NPE ，是程序员的基本修养，注意 NPE 产生的场景：

 - 返回类型为包装数据类型，有可能是 null ，返回 int 值时注意判空；反例： public int f() {  return Integer 对象}; 如果为 null ，自动解箱抛 NPE ；

 - 数据库的查询结果可能为 null ；

 - 集合里的元素即使 isNotEmpty ，取出的数据元素也可能为 null ；

 - 远程调用返回对象，一律要求进行 NPE 判断；

 - 对于 Session 中获取的数据，建议 NPE 检查，避免空指针；

 - 级联调用 obj . getA() . getB() . getC()； 一连串调用，易产生 NPE 。

26、可以使用 warn 日志级别来记录用户输入参数错误的情况，避免用户投诉时，无所适从；注意日志输出的级别， error 级别只记录系统逻辑出错、异常等重要的错误信息；如非必要，请不要在此场景打出 error 级别；

27、大量地输出无效日志，不利于系统性能提升，也不利于快速定位错误点；记录日志时请思考：这些日志真的有人看吗？看到这条日志你能做什么？能不能给问题排查带来好处？

28、表达是与否概念的字段，必须使用 is _ xxx 的方式命名，数据类型是 unsigned tinyint（ 1 表示是，0 表示否 ） ，此规则同样适用于 odps 建表；说明：任何字段如果为非负数，必须是 unsigned ；

29、唯一索引名为 uk _字段名 ； 普通索引名则为 idx _字段名；说明： uk _ 即  unique key；idx _ 即 index 的简称；

30、小数类型为 decimal ，禁止使用 float 和 double ；

31、如果存储的字符串长度几乎相等，使用 char 定长字符串类型；

32、varchar 是可变长字符串，不预先分配存储空间，长度不要超过 5000，如果存储长度大于此值，定义字段类型为 text ，独立出来一张表，用主键来对应，避免影响其它字段索引效率；

33、表必备三字段： id ,  gmt _ create ,  gmt _ modified ；说明：其中 id 必为主键，类型为 unsigned bigint 、单表时自增、步长为 1； gmt _ create ,gmt _ modified 的类型均为 date _ time 类型；

34、单表行数超过 500 万行或者单表容量超过 2 GB ，才推荐进行分库分表；如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表；

35、合适的字符存储长度，不但节约数据库表空间、节约索引存储，更重要的是提升检索速度：

 - 人的年龄用 unsigned tinyint（ 表示范围 0-255，人的寿命不会超过 255 岁 ）； 
 
 - 海龟就必须是 smallint ；
 
 - 如果是太阳的年龄，就必须是 int； 
 
 - 如果是所有恒星的年龄都加起来，那么就必须使用 bigint ；

36、超过三个表禁止 join ；需要 join 的字段，数据类型保持绝对一致 ； 多表关联查询时，保证被关联的字段需要有索引；说明：即使双表 join 也要注意表索引、 SQL 性能

37、在 varchar 字段上建立索引时，必须指定索引长度，没必要对全字段建立索引，根据实际文本区分度决定索引长度；说明：索引的长度与区分度是一对矛盾体，一般对字符串类型数据，长度为 20 的索引，区分度会高达 90%以上，可以使用 count(distinct left( 列名, 索引长度 )) / count( * ) 的区分度来确定；

38、页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决；说明：索引文件具有 B - Tree 的最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引；

39、如果有 order by 的场景，请注意利用索引的有序性； order by 最后的字段是组合索引的一部分，并且放在索引组合顺序的最后，避免出现 file _ sort 的情况，影响查询性能；

 - 正例：where a =?  and b =?  order by c; 索引： a _ b _ c

 - 反例：索引中有范围查找，那么索引有序性无法利用，如： WHERE a >10  ORDER BY b; 索引a _ b 无法排序；

40、利用覆盖索引来进行查询操作，来避免回表操作；说明：如果一本书需要知道第 11 章是什么标题，会翻开第 11 章对应的那一页吗？目录浏览一下就好，这个目录就是起到覆盖索引的作用；正例：能够建立索引的种类：主键索引、唯一索引、普通索引，而覆盖索引是一种查询的一种效果，用 explain 的结果， extra 列会出现： using index ；

41、利用延迟关联或者子查询优化超多分页场景；说明： MySQL 并不是跳过 offset 行，而是取 offset + N 行，然后返回放弃前 offset 行，返回N 行，那当 offset 特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行 SQL 改写；

42、SQL 性能优化的目标：至少要达到  range 级别，要求是 ref 级别，如果可以是 consts最好：

 - consts 单表中最多只有一个匹配行 （ 主键或者唯一索引 ） ，在优化阶段即可读取到数据；

 - ref 指的是使用普通的索引 （normal index） ；

 - range 对索引进行范围检索；

 - 反例： explain 表的结果， type = index ，索引物理文件全扫描，速度非常慢，这个 index 级别比较 range 还低，与全表扫描是小巫见大巫；

43、建组合索引的时候，区分度最高的在最左边：

 - 正例：如果 where a =?  and b =? ， a 列的几乎接近于唯一值，那么只需要单建 idx _ a 索引即可；说明：存在非等号和等号混合判断条件时，在建索引时，请把等号条件的列前置；如： where a >?and b =? 那么即使 a 的区分度更高，也必须把 b 放在索引的最前列；

44、不要使用 count( 列名 ) 或 count( 常量 ) 来替代 count( * ) ， count( * ) 就是 SQL 92 定义的标准统计行数的语法，跟数据库无关，跟 NULL 和非 NULL 无关；说明： count( * ) 会统计值为 NULL 的行，而 count( 列名 ) 不会统计此列为 NULL 值的行；

45、count(distinct col) 计算该列除 NULL 之外的不重复数量；注意  count(distinct col 1,  col 2 ) 如果其中一列全为 NULL ，那么即使另一列有不同的值，也返回为 0；

46、当某一列的值全是 NULL 时， count(col) 的返回结果为 0，但 sum(col) 的返回结果为NULL ，因此使用 sum() 时需注意 NPE 问题；正例：可以使用如下方式来避免 sum 的 NPE 问题： SELECT IF(ISNULL(SUM(g)) ,0, SUM(g)) FROM table;

47、使用 ISNULL() 来判断是否为 NULL 值；

48、在代码中写分页查询逻辑时，若 count 为 0 应直接返回，避免执行后面的分页语句；

49、禁止使用存储过程，存储过程难以调试和扩展，更没有移植性；

50、in 操作能避免则避免，若实在避免不了，需要仔细评估 in 后边的集合元素数量，控制在 1000 个之内；

51、如果有全球化需要，所有的字符存储与表示，均以 utf -8 编码，那么字符计数方法注意：

 - SELECT LENGTH( "轻松工作" )； 返回为 12

 - SELECT CHARACTER _ LENGTH( "轻松工作" )； 返回为 4

 - 如果要使用表情，那么使用 utfmb 4 来进行存储，注意它与 utf -8 编码的区别；

52、TRUNCATE TABLE 比  DELETE 速度快，且使用的系统和事务日志资源少，但 TRUNCATE 无事务且不触发 trigger ，有可能造成事故，故不建议在开发代码中使用此语句；说明： TRUNCATE TABLE 在功能上与不带  WHERE 子句的  DELETE 语句相同

53、xml 配置中参数注意使用：#{}，# param # 不要使用${}

54、iBATIS 自带的 queryForList(String statementName , int start , int size) 不推荐使用；说明：其实现方式是在数据库取到 statementName 对应的 SQL 语句的所有记录，再通过 subList取 start , size 的子集合，线上因为这个原因曾经出现过 OOM ；正例：在 sqlmap . xml 中引入 #start#, #size#

55、< isEqual >中的 compareValue 是与属性值对比的常量，一般是数字，表示相等时带上此条件 ； < isNotEmpty >表示不为空且不为 null 时执行 ； < isNotNull >表示不为 null 值时执行；

56、高并发服务器建议调小 TCP 协议的 time _ wait 超时时间；说明：操作系统默认 240 秒后，才会关闭处于 time _ wait 状态的连接，在高并发访问下，服务器端会因为处于 time _ wait 的连接数太多，可能无法建立新的连接，所以需要在服务器上调小此等待值；
在 linux 服务器上请通过变更/ etc / sysctl . conf 文件去修改该缺省值 （ 秒 ） ：
net . ipv 4. tcp _ fin _ timeout = 30

57、调大服务器所支持的最大文件句柄数 （File Descriptor ，简写为 fd）:

 - 主流操作系统的设计是将 TCP / UDP 连接采用与文件一样的方式去管理，即一个连接对应于一个 fd ；
 
 - 主流的 linux 服务器默认所支持最大 fd 数量为 1024，当并发连接数很大时很容易因为 fd 不足而出现“ open too many files ”错误，导致新的连接无法建立； 

 - 建议将 linux服务器所支持的最大句柄数调高数倍 （ 与服务器的内存数量相关 ）。

58、给 JVM 设置- XX :+ HeapDumpOnOutOfMemoryError 参数，让 JVM 碰到 OOM 场景时输出dump 信息: OOM 的发生是有概率的，甚至有规律地相隔数月才出现一例，出现时的现场信息对查错非常有价值

59、服务器内部重定向使用 forward； 外部重定向地址使用 URL 拼装工具类来生成，否则会带来 URL 维护不一致的问题和潜在的安全风险；

60、用户请求传入的任何参数必须做有效性验证，忽略参数校验可能导致：

 - page size 过大导致内存溢出；

 - 恶意 order by 导致数据库慢查询；

 - 任意重定向；

 - SQL 注入；

 - 反序列化注入；

 - 正则输入源串拒绝服务 ReDoS。

61、表单、 AJAX 提交必须执行 CSRF 安全过滤。